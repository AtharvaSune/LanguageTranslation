# LanguageTranslation

Language Translation from French to English using Attention Layer

<img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Feeding-Hidden-State-as-Input-to-Decoder.png">

RNN have long been good at time series related tasks, where the current output depend on an input that was seen earlier
For language Translation we can use a normal encoder decoder model, but using the attention layer a much better performance is observed.
